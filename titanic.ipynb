{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make a copy of the original dataframe\nSo when we manipulate the copy, we've still got our original data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a copy of the original dataframe to perform edits on.\ndf_tmp = train_data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the values of different columns\ndf_tmp.Ticket.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_tmp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Manipulate the Data into numbers"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp[\"Name\"].dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Convert string into categories\nOne way we can turn all of our data into numbers is by converting them into pandas categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the columns wich contain strings\nfor label, content in df_tmp.items():\n    if pd.api.types.is_string_dtype(content):\n        df_tmp[label] = content.astype(\"category\").cat.as_ordered()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.Name.cat.categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.Name.cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the missing data\ndf_tmp.isnull().sum()/len(df_tmp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fill the missing values first\nFill numerical values first"},{"metadata":{"trusted":true},"cell_type":"code","source":"for label, content in df_tmp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for which numeric columns have null values\nfor label, content in df_tmp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill numeric rows with the median\nfor label, content in df_tmp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            # Add a binary column which tells is the data is missing or not\n            # df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n            # Fill the missing numeric values with median\n            df_tmp[label] = content.fillna(content.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if there's any null numeric values\nfor label, content in df_tmp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Filling and turning categorical variables into numbers"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for columns which aren't numeric\nfor label, content in df_tmp.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        # Add binary column to indicate whether sample had missing value\n        # df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n        # Turn categories into numbers and add +1\n        df_tmp[label] = pd.Categorical(content).codes+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Categorical(df_tmp[\"Cabin\"]).codes+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split Data into X and y\nX = df_tmp.drop(\"Survived\", axis=1)\n\ny = df_tmp[\"Survived\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import all the tools we need\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# we want our plots to appear inside the notebook\n%matplotlib inline \n\n# Models from Scikit-Learn\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Model Evaluations\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n#from sklearn.metrics import confusion_matrix, classification_report\n#from sklearn.metrics import precision_score, recall_score, f1_score\n#from sklearn.metrics import plot_roc_curve\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split data into train and validation sets\nnp.random.seed(42)\n\n# Split into train & test set\nX_train, X_val, y_train, y_val = train_test_split(X,\n                                                    y,\n                                                    test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train, len(y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## Modelling\n\nNow we've got our data into training and validation sets, it's time to build the model.\n\nWe'll train it (find the patterns) on the training set.\n\nAnd we'll validate it (use the patterns) on the test set.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\n \nclf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=70)\nclf.fit(X, y)\n\nclf.score(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's try XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgb_model = XGBClassifier()\nxgb_model.fit(X, y)\n\nxgb_model.score(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now Naive Bayes"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\ngnb_model = GaussianNB()\ngnb_model.fit(X, y)\n\ngnb_model.score(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Let's convert the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# First we'll copy the test data to protest the original data\ndf_test = test_data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the columns wich contain strings\nfor label, content in df_test.items():\n    if pd.api.types.is_string_dtype(content):\n        df_test[label] = content.astype(\"category\").cat.as_ordered()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the missing data\ndf_test.isnull().sum()/len(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill numeric values first\nfor label, content in df_test.items():\n    if pd.api.types.is_numeric_dtype(content):\n        print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for which numeric columns have null values\nfor label, content in df_test.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill numeric rows with the median\nfor label, content in df_test.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            # Add a binary column which tells is the data is missing or not\n            # df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n            # Fill the missing numeric values with median\n            df_test[label] = content.fillna(content.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if there's any null numeric values\nfor label, content in df_test.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for columns which aren't numeric\nfor label, content in df_test.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        # Add binary column to indicate whether sample had missing value\n        # df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n        # Turn categories into numbers and add +1\n        df_test[label] = pd.Categorical(content).codes+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Categorical(df_test[\"Cabin\"]).codes+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.predict(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions = clf.predict(df_test)#\n\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n#output.to_csv('925A_submission.csv', index=False)\n#print(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_model.predict(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions = xgb_model.predict(df_test)\n\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n#output.to_csv('xgb_submission.csv', index=False)\n#print(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gnb_model.predict(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions = gnb_model.predict(df_test)\n\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n#output.to_csv('gnb_submission.csv', index=False)\n#print(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's reformat the data with relevant information"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's look at the orignal format to test the data\n# features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"]\n#X = pd.get_dummies(train_data[features])\n#X_test = pd.get_dummies(test_data[features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What does our data look like now?\nX.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# What are the data definitions?\nData Dictionary\nVariable\tDefinition\t    Key\n\nsurvival\tSurvival\t    0 = No, 1 = Yes\n\npclass\t    Ticket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n\nsex\t        Sex\t\n\nAge\t        Age in years\t\n\nsibsp\t    # of siblings / spouses aboard the Titanic\t\n\nparch\t    # of parents / children aboard the Titanic\t\n\nticket\t    Ticket number\t\n\nfare\t    Passenger fare\t\n\ncabin\t    Cabin number\t\n\nembarked\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n\n### In the original data the model only tested on these features: features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\"] \n### Let's test our models on all of the features: [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\", \"Age\", \"ticket\", \"fare\"]\nWe'll drop \"Name\" and \"SibSp\""},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reformat\nX = X.drop(\"Name\", axis=1)\nX = X.drop(\"SibSp\", axis=1)\n#X=  X.drop(\"Embarked\", axis=1)\nX.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reformat df_test\ndf_test = df_test.drop(\"Name\", axis=1)\ndf_test = df_test.drop(\"SibSp\", axis=1)\n#df_test = df_test.drop(\"Embarked\", axis=1)\ndf_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's try our models again with the new reformatted data\nclf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=70)\nclf.fit(X, y)\n\nclf.score(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 63%"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Next\nxgb_model = XGBClassifier()\nxgb_model.fit(X, y)\n\nxgb_model.score(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tough to tell. This one scored perfect the first time. Overfit, probably."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Next\ngnb_model = GaussianNB()\ngnb_model.fit(X, y)\n\ngnb_model.score(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 79%\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's try this one again with increasing the iterations as recommended\nclf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=150)\nclf.fit(X, y)\n\nclf.score(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Even better. 6 percent up."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's try RandomForestClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\nrf.fit(X, y)\n\nrf.score(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Yes! That looks good!\n## Let's submit a test"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = rf.predict(df_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('rf_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Let's Tune the Hyperparamaters on the RandomForestModel. Best score so far, but still at 77%."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create a hyperparameter grid for RandomForestClassifier\n#rf_grid = {\"n_estimators\": np.arange(10, 1000, 50),\n#           \"max_depth\": [None, 3, 5, 10],\n#          \"min_samples_split\": np.arange(2, 20, 2),\n#         \"min_samples_leaf\": np.arange(1, 20, 2)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setup random seed\n#np.random.seed(42)\n\n# Setup random hyperparameter search for RandomForestClassifier\n#rs_rf = RandomizedSearchCV(RandomForestClassifier(), \n#                           param_distributions=rf_grid,\n#                           cv=5,\n#                           n_iter=20,\n#                           verbose=True)\n\n# Fit random hyperparameter search model for RandomForestClassifier()\n#rs_rf.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the best hyperparameters\n#rs_rf.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rs_rf.score(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Nice! 90%. Let's submit this one."},{"metadata":{"trusted":true},"cell_type":"code","source":"#predictions = rs_rf.predict(df_test)\n\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n#output.to_csv('rs_rf_submission.csv', index=False)\n#print(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Okay, that one came back @ 77%. Hmmm.\n# Let's try Logistic Regression and Hypertune parameters. "},{"metadata":{"trusted":true},"cell_type":"code","source":"#log_reg_model = LogisticRegression()\n#log_reg_model.fit(X, y)\n\n#log_reg_model.score(X, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Not bad. 78% and it stopped. Let's tune it now."},{"metadata":{"trusted":true},"cell_type":"code","source":"#log_reg_grid = {\"C\": np.logspace(-4, 4, 20),\n#                \"solver\": [\"liblinear\"]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we've set up a grid, let's hypertune!\n\n#np.random.seed(42)\n\n# Setup random hyperparameter search for LogisticRegression\n#rs_log_reg = RandomizedSearchCV(LogisticRegression(),\n#                                param_distributions=log_reg_grid,\n#                                cv=5,\n#                                n_iter=20,\n#                                verbose=True)\n\n# Fit random hyperparameter search model for LogisticRegression\n#rs_log_reg.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rs_log_reg.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rs_log_reg.score(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Let's see if we can improve 80% with GridSearchCV\n# Different hyperparameters for our LogisticRegression model\n#log_reg_grid = {\"C\": np.logspace(-4, 4, 30),\n#                \"solver\": [\"liblinear\"]}\n\n# Setup grid hyperparameter search for LogisticRegression\n#gs_log_reg = GridSearchCV(LogisticRegression(),\n#                          param_grid=log_reg_grid,\n#                          cv=5,\n#                          verbose=True)\n\n# Fit grid hyperparameter search model\n#gs_log_reg.fit(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check the best hyperparmaters\n#gs_log_reg.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the grid search LogisticRegression model\n#gs_log_reg.score(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Same, but's let's see what the actual comes back at us\n#predictions = gs_log_reg.predict(df_test)\n\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n#output.to_csv('gslogreg_submission.csv', index=False)\n#print(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 75% Let's try Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.tree import DecisionTreeClassifier\n#dtc_model = DecisionTreeClassifier(random_state=42)\n\n#dtc_model.fit(X, y)\n\n#dtc_model.score(X, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overfit? Let's submit anyway\n#predictions = dtc_model.predict(df_test)\n\n#output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n#output.to_csv('dtc_model_submission.csv', index=False)\n#print(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}